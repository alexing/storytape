{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Walking Dead Compendium Volume 3 (Walking ...</td>\n",
       "      <td>Robert Kirkman</td>\n",
       "      <td>Comics &amp; Graphic Novels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saga Volume 5 (Saga Tp)</td>\n",
       "      <td>Brian K. Vaughan</td>\n",
       "      <td>Comics &amp; Graphic Novels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead:  Compendium One</td>\n",
       "      <td>Robert Kirkman</td>\n",
       "      <td>Comics &amp; Graphic Novels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Batman: The Killing Joke, Deluxe Edition</td>\n",
       "      <td>Alan Moore</td>\n",
       "      <td>Comics &amp; Graphic Novels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Walking Dead: Compendium Two</td>\n",
       "      <td>Robert Kirkman</td>\n",
       "      <td>Comics &amp; Graphic Novels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title            Author  \\\n",
       "0  The Walking Dead Compendium Volume 3 (Walking ...    Robert Kirkman   \n",
       "1                            Saga Volume 5 (Saga Tp)  Brian K. Vaughan   \n",
       "2                  The Walking Dead:  Compendium One    Robert Kirkman   \n",
       "3           Batman: The Killing Joke, Deluxe Edition        Alan Moore   \n",
       "4                   The Walking Dead: Compendium Two    Robert Kirkman   \n",
       "\n",
       "                     Genre  \n",
       "0  Comics & Graphic Novels  \n",
       "1  Comics & Graphic Novels  \n",
       "2  Comics & Graphic Novels  \n",
       "3  Comics & Graphic Novels  \n",
       "4  Comics & Graphic Novels  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/books-dataset.zip', encoding='latin-1', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "books = df[['Title', 'Author']]\n",
    "genres = df[['Genre']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books.fillna('No Book')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag (Genre) Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_encoder = LabelEncoder()\n",
    "genre_encoder.fit(np.ravel(genres))\n",
    "encoded_genres = genre_encoder.transform(np.ravel(genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  3,  3, ..., 14, 14, 14], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Comics & Graphic Novels'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_encoder.inverse_transform(encoded_genres[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = encoded_genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_encoder = LabelEncoder()\n",
    "author_encoder.fit(np.ravel(books.Author))\n",
    "encoded_authors = author_encoder.transform(np.ravel(books.Author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features['encoded_author'] = encoded_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Robert Kirkman'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_encoder.inverse_transform(encoded_authors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['book_info'] = books.Author + ' ' + books.Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "english_stopwords = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format(title, stopwords=english_stopwords):\n",
    "    split_title = title.split()\n",
    "    return ' '.join([(x) for x in split_title if x not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features['book_info'] = features.book_info.apply(format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robert Kirkman The Walking Dead Compendium Vol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian K. Vaughan Saga Volume 5 (Saga Tp)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert Kirkman The Walking Dead: Compendium One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alan Moore Batman: The Killing Joke, Deluxe Ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robert Kirkman The Walking Dead: Compendium Two</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           book_info\n",
       "0  Robert Kirkman The Walking Dead Compendium Vol...\n",
       "1           Brian K. Vaughan Saga Volume 5 (Saga Tp)\n",
       "2    Robert Kirkman The Walking Dead: Compendium One\n",
       "3  Alan Moore Batman: The Killing Joke, Deluxe Ed...\n",
       "4    Robert Kirkman The Walking Dead: Compendium Two"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', token_pattern=r'\\w+', ngram_range=(1,1), min_df=1,\n",
    "                             strip_accents='unicode', max_features=25000, binary=True, sublinear_tf=True)\n",
    "vectors = vectorizer.fit_transform(features.book_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<101061x25000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 755031 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def test_model(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Results for train set:\")\n",
    "    pred_train = clf.predict(X_train)\n",
    "    print(metrics.classification_report(y_train, pred_train))\n",
    "    print(\"Results for test set:\")\n",
    "    pred_test = clf.predict(X_test)\n",
    "    print(metrics.classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(vectors, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for train set:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.61      0.65      3198\n",
      "          1       0.86      0.90      0.88      7457\n",
      "          2       0.70      0.87      0.78     10252\n",
      "          3       0.88      0.68      0.77      2306\n",
      "          4       0.94      0.25      0.39      1006\n",
      "          5       0.74      0.79      0.76      5084\n",
      "          6       0.79      0.74      0.77      5140\n",
      "          7       0.63      0.77      0.69      5734\n",
      "          8       0.82      0.49      0.62      2549\n",
      "          9       0.78      0.83      0.81      5739\n",
      "         10       0.78      0.77      0.78      3264\n",
      "         11       0.87      0.69      0.77      2821\n",
      "         12       0.84      0.61      0.70      2024\n",
      "         13       0.74      0.66      0.70      5562\n",
      "         14       0.90      0.90      0.90     13659\n",
      "\n",
      "avg / total       0.79      0.78      0.78     75795\n",
      "\n",
      "Results for test set:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.35      0.39      1063\n",
      "          1       0.79      0.85      0.82      2508\n",
      "          2       0.62      0.80      0.70      3353\n",
      "          3       0.81      0.58      0.68       720\n",
      "          4       0.82      0.13      0.22       333\n",
      "          5       0.61      0.65      0.63      1723\n",
      "          6       0.65      0.59      0.62      1756\n",
      "          7       0.48      0.62      0.54      1846\n",
      "          8       0.56      0.29      0.38       853\n",
      "          9       0.67      0.73      0.70      1820\n",
      "         10       0.66      0.67      0.66      1027\n",
      "         11       0.76      0.55      0.64       979\n",
      "         12       0.68      0.44      0.54       679\n",
      "         13       0.57      0.52      0.54      1927\n",
      "         14       0.87      0.85      0.86      4679\n",
      "\n",
      "avg / total       0.68      0.67      0.67     25266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = BernoulliNB(alpha=0.5)\n",
    "test_model(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Children's Books\""
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_encoder.inverse_transform(clf.predict(vectorizer.transform(['King Arthur'])))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for train set:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.40      0.53      3205\n",
      "          1       0.75      0.92      0.83      7503\n",
      "          2       0.61      0.88      0.72     10158\n",
      "          3       0.92      0.53      0.67      2285\n",
      "          4       0.97      0.16      0.28      1010\n",
      "          5       0.71      0.73      0.72      5092\n",
      "          6       0.79      0.67      0.73      5116\n",
      "          7       0.68      0.66      0.67      5707\n",
      "          8       0.88      0.31      0.46      2590\n",
      "          9       0.72      0.83      0.77      5733\n",
      "         10       0.84      0.61      0.70      3236\n",
      "         11       0.91      0.57      0.70      2792\n",
      "         12       0.90      0.39      0.54      2008\n",
      "         13       0.72      0.57      0.63      5607\n",
      "         14       0.77      0.95      0.85     13753\n",
      "\n",
      "avg / total       0.75      0.73      0.72     75795\n",
      "\n",
      "Results for test set:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.20      0.29      1056\n",
      "          1       0.69      0.88      0.77      2462\n",
      "          2       0.52      0.80      0.63      3447\n",
      "          3       0.87      0.41      0.56       741\n",
      "          4       0.90      0.08      0.15       329\n",
      "          5       0.60      0.61      0.60      1715\n",
      "          6       0.68      0.51      0.58      1780\n",
      "          7       0.50      0.49      0.50      1873\n",
      "          8       0.64      0.18      0.28       812\n",
      "          9       0.61      0.73      0.67      1826\n",
      "         10       0.67      0.43      0.52      1055\n",
      "         11       0.80      0.40      0.53      1008\n",
      "         12       0.83      0.30      0.44       695\n",
      "         13       0.51      0.38      0.44      1882\n",
      "         14       0.72      0.92      0.81      4585\n",
      "\n",
      "avg / total       0.64      0.63      0.60     25266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=0.5)\n",
    "test_model(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Literature & Fiction'"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_encoder.inverse_transform(clf.predict(vectorizer.transform(['The Part and  the Whole Ernest Heisenberg'])))[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
